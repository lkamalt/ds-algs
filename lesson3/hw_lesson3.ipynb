{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792234db",
   "metadata": {},
   "source": [
    "# Логистическая регрессия. Log Loss<a class='anchor' id='log_regr'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b50343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fefa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standartization(X):\n",
    "    \"\"\" Стандартизация \"\"\"\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a5f82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Признаки\n",
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450, 800, 1500, 2000, 450, 1000],\n",
    "              [21, 25, 27, 20, 25,  18, 35, 60, 20, 30]], dtype = np.float64).T\n",
    "# Целевая переменная\n",
    "y = np.array([0, 0, 0, 1, 1, 1, 1, 0, 0, 0], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b3b131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 1.00e+00, 5.00e+02, 2.10e+01],\n",
       "       [1.00e+00, 1.00e+00, 7.00e+02, 2.50e+01],\n",
       "       [1.00e+00, 2.00e+00, 7.50e+02, 2.70e+01],\n",
       "       [1.00e+00, 1.00e+00, 6.00e+02, 2.00e+01],\n",
       "       [1.00e+00, 3.00e+00, 1.45e+03, 2.50e+01],\n",
       "       [1.00e+00, 0.00e+00, 8.00e+02, 1.80e+01],\n",
       "       [1.00e+00, 5.00e+00, 1.50e+03, 3.50e+01],\n",
       "       [1.00e+00, 1.00e+01, 2.00e+03, 6.00e+01],\n",
       "       [1.00e+00, 1.00e+00, 4.50e+02, 2.00e+01],\n",
       "       [1.00e+00, 2.00e+00, 1.00e+03, 3.00e+01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b76d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.57142857, -0.97958969, -0.60595294],\n",
       "       [ 1.        , -0.57142857, -0.56713087, -0.264571  ],\n",
       "       [ 1.        , -0.21428571, -0.46401617, -0.09388003],\n",
       "       [ 1.        , -0.57142857, -0.77336028, -0.69129842],\n",
       "       [ 1.        ,  0.14285714,  0.97958969, -0.264571  ],\n",
       "       [ 1.        , -0.92857143, -0.36090146, -0.86198939],\n",
       "       [ 1.        ,  0.85714286,  1.08270439,  0.58888384],\n",
       "       [ 1.        ,  2.64285714,  2.11385144,  2.72252095],\n",
       "       [ 1.        , -0.57142857, -1.08270439, -0.69129842],\n",
       "       [ 1.        , -0.21428571,  0.05155735,  0.16215642]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проведем стандартизацию признаков\n",
    "X_st = X.copy()\n",
    "X_st[:, 1:] = standartization(X[:, 1:])\n",
    "X_st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c6dbc",
   "metadata": {},
   "source": [
    "### Задание 1 <a class='anchor' id='log_regr1'>\n",
    "\n",
    "Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log (как вариант - использовать np.clip или np.where)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fecc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss_init(y, y_pred):\n",
    "    \"\"\" Вариант расчета без фильтрации \"\"\"\n",
    "    # Считаем ошибку\n",
    "    err = np.mean(-y * np.log(y_pred) - (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c6f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred, debug=False):\n",
    "    \"\"\" Вариант расчета с фильтрацией некорректных значений \"\"\"\n",
    "    # Индексы элементов, которые не равны 1 или 0     \n",
    "    I = np.where((y_pred != 0) & (y_pred != 1))\n",
    "    \n",
    "    # Фильтруем массивы, убраем 0 и 1 в y_pred, оставляем те же индексы в списке y\n",
    "    y_pred = y_pred[I]\n",
    "    y = y[I]\n",
    "    \n",
    "    # Проверка\n",
    "    if debug:\n",
    "        print(f'y_pred = {y_pred}\\ny = {y}')\n",
    "    \n",
    "    # Считаем ошибку\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    err = np.sum(err)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85af53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверочные списки\n",
    "y_test = np.array([1, 0, 1, 0])\n",
    "y_pred_test = np.array([0, 1, 0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b5c512f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss = inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_10304/1595593995.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  err = np.mean(-y * np.log(y_pred) - (1.0 - y) * np.log(1.0 - y_pred))\n"
     ]
    }
   ],
   "source": [
    "# Проверим, что выдает ошибку если в y_pred есть 0 и 1\n",
    "error = calc_logloss_init(y_test, y_pred_test)\n",
    "print(f'log_loss = {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36470e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred = [0.9 0.1]\n",
      "y = [1 0]\n",
      "log_loss = 0.10536051565782628\n"
     ]
    }
   ],
   "source": [
    "# В этом варианте, 1 и 0 в y_pred должны отсеяться и останется только корректные значения [0.9, 0.1]\n",
    "# список y тоже отфильтровываем по маске списка y_pred\n",
    "error = calc_logloss(y_test, y_pred_test, True)\n",
    "print(f'log_loss = {error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d07fa",
   "metadata": {},
   "source": [
    "### Задание 2 <a class='anchor' id='log_regr2'>\n",
    "\n",
    "На данных из урока изучите влияние гиперпараметров на ошибку алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0fa433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\" Вычисляет вероятность \"\"\"\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2942464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_LR_model(X, y, iterations, eta=1e-4):\n",
    "    \"\"\" Логистическая регрессия \"\"\"\n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    for i in range(1, iterations + 1):\n",
    "        z = np.dot(X, w)\n",
    "        pred = sigmoid(z)\n",
    "        w -= eta * (1 / n * np.dot((pred - y), X))\n",
    "        err = calc_logloss(y, sigmoid(np.dot(X, w)))\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(f'Iteration = {i}, w = {w}, error = {err}')\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76bdd618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 10, w = [ 0.36065583 -0.3972585   0.51937535  1.19161524], error = 0.972199021173242\n",
      "Iteration = 20, w = [ 0.215788   -0.61251766  0.44159174  0.90102578], error = 0.8152129340815597\n",
      "Iteration = 30, w = [ 0.08277136 -0.76559453  0.42551123  0.67107078], error = 0.7212678942568461\n",
      "Iteration = 40, w = [-0.02507329 -0.85541749  0.46585326  0.50463174], error = 0.6722796074198796\n",
      "Iteration = 50, w = [-0.10912684 -0.90576455  0.53830407  0.37884616], error = 0.6416699927595096\n",
      "Iteration = 60, w = [-0.17469927 -0.93640342  0.62421319  0.27424279], error = 0.6181685428656378\n",
      "Iteration = 70, w = [-0.22617113 -0.95733883  0.71436092  0.18090474], error = 0.5982903907109156\n",
      "Iteration = 80, w = [-0.26681997 -0.97319728  0.80460517  0.09421158], error = 0.5807656397146188\n",
      "Iteration = 90, w = [-0.29911987 -0.98614533  0.89312045  0.01196478], error = 0.5649873364632754\n",
      "Iteration = 100, w = [-0.32495521 -0.99723356  0.97913034 -0.06693668], error = 0.5506011060815837\n"
     ]
    }
   ],
   "source": [
    "# Вычисление весов\n",
    "w = eval_LR_model(X_st, y, iterations=100, eta=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d1db4",
   "metadata": {},
   "source": [
    "При увеличении скорости обучения eta алгоритм быстрее сходится и ошибка уменьшается при том же количестве итераций = 100. \n",
    "\n",
    "Например, (iterations = 100):\n",
    "    \n",
    "    eta = 0.1, error = 0.55\n",
    "    \n",
    "    eta = 0.7, error = 0.29.\n",
    "\n",
    "Также видно, что при увеличении скорости обучения, веса тоже увеличиваются по модулю.\n",
    "\n",
    "При увеличении числа итераций и неизменном значении eta ошибка также уменьшается. \n",
    "\n",
    "Например, (eta = 0.1): \n",
    "\n",
    "    iterations = 100, error = 0.55\n",
    "\n",
    "    iterations = 500, error = 0.33."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca9829",
   "metadata": {},
   "source": [
    "### Задание 3 <a class='anchor' id='log_regr3'>\n",
    "\n",
    "Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса \"1\". На вход функции подаются значения признаков Х и веса, которые уже посчитаны функцией eval_LR_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f01ea61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(X, w):\n",
    "    \"\"\" Вычисляет вероятность класса 1 \"\"\"\n",
    "    return sigmoid(np.dot(X, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "929f33c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob = [0.34 0.43 0.36 0.39 0.62 0.58 0.46 0.25 0.32 0.48]\n"
     ]
    }
   ],
   "source": [
    "# Проверка функции\n",
    "prob = calc_pred_proba(X_st, w)\n",
    "print(f'prob = {prob.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6236eecb",
   "metadata": {},
   "source": [
    "### Задание 4 <a class='anchor' id='log_regr4'>\n",
    "\n",
    "Создайте функцию calc_pred, возвращающую предсказанные классы (0 или 1). На вход функции подаются значения признаков Х и веса, которые уже посчитаны функцией eval_LR_model, а также порог вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca30608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(X, w, prob_threshold=0.5):\n",
    "    \"\"\" По предсказанной вероятности и порогу вычисляет класс - 0 или 1 \"\"\"\n",
    "    pred = calc_pred_proba(X, w)\n",
    "    return np.where(pred > prob_threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb9f0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes = [0 0 0 0 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Проверка функции\n",
    "classes = calc_pred(X_st, w)\n",
    "print(f'classes = {classes}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
